{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14eb3e52",
   "metadata": {},
   "source": [
    "# Data Integration & EDA\n",
    "## Power Outage Prediction Analysis\n",
    "\n",
    "This notebook performs data integration and exploratory data analysis on cleaned weather and outage datasets.\n",
    "\n",
    "**Input**: Cleaned weather and outage data from data loading notebook\n",
    "**Output**: Integrated dataset and statistical analysis ready for modeling\n",
    "\n",
    "**Sections**:\n",
    "- Data loading and integration \n",
    "- Geographic reporting bias analysis\n",
    "- Exploratory data analysis\n",
    "- Statistical summaries and correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aee203",
   "metadata": {},
   "source": [
    "## Load Cleaned Data\n",
    "\n",
    "First, load the cleaned datasets from the data loading notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8afe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned datasets\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Load data helper function\n",
    "def load_cleaned_data():\n",
    "    \"\"\"Load cleaned weather and outage datasets from CSV files\"\"\"\n",
    "    data_dir = Path(\"../../data/processed\")\n",
    "    weather_file = data_dir / \"weather_cleaned.csv\"\n",
    "    outage_file = data_dir / \"outages_cleaned.csv\"\n",
    "    \n",
    "    if weather_file.exists() and outage_file.exists():\n",
    "        weather_df = pd.read_csv(weather_file)\n",
    "        outage_df = pd.read_csv(outage_file)\n",
    "        \n",
    "        # Convert date columns back to datetime\n",
    "        weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "        outage_df['date'] = pd.to_datetime(outage_df['date'])\n",
    "        outage_df['run_start_time'] = pd.to_datetime(outage_df['run_start_time'])\n",
    "        \n",
    "        return weather_df, outage_df\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No cleaned data files found - run data cleaning first\")\n",
    "\n",
    "# Load the data\n",
    "weather_pivot, outage_clean = load_cleaned_data()\n",
    "\n",
    "print(\"Data loaded successfully\")\n",
    "print(f\"Weather data: {weather_pivot.shape}\")\n",
    "print(f\"Outage data: {outage_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f08d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131bf76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outage_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd139ec6",
   "metadata": {},
   "source": [
    "## Data Integration\n",
    "\n",
    "Merge weather and outage datasets, creating a complete analysis-ready dataset.\n",
    "\n",
    "**Integration Strategy**\n",
    "- Left join weather data (complete coverage) with outage data (partial coverage)\n",
    "- Filter to counties with verified outage reporting to avoid bias\n",
    "- Clean geographic identifiers for consistent analysis\n",
    "\n",
    "**Key Processing Steps**\n",
    "1. Merge datasets on fips_code and date\n",
    "2. Fill missing outage indicators (NaN = no outage)\n",
    "3. Restrict to counties with demonstrated reporting capability\n",
    "4. Extract clean geographic names from weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a20f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Integration - Merge weather and outage datasets\n",
    "print(\"Integrating weather and outage datasets...\")\n",
    "\n",
    "# Merge weather and outage data (left join to preserve all weather observations)\n",
    "merged_df = weather_pivot.merge(\n",
    "    outage_clean[['fips_code', 'date', 'outage_occurred', 'customers_out', 'county', 'state', 'run_start_time']], \n",
    "    on=['fips_code', 'date'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values for outage indicators (NaN = no outage occurred)\n",
    "merged_df['outage_occurred'] = merged_df['outage_occurred'].fillna(0).astype(int)\n",
    "merged_df['customers_out'] = merged_df['customers_out'].fillna(0).astype(int)\n",
    "\n",
    "# Filter to counties with outage reporting systems to avoid statistical bias\n",
    "counties_with_reporting = set(outage_clean['fips_code'].unique())\n",
    "merged_df = merged_df[merged_df['fips_code'].isin(counties_with_reporting)].copy()\n",
    "\n",
    "print(f\"Final dataset: {merged_df.shape}\")\n",
    "print(f\"Counties included: {merged_df['fips_code'].nunique():,}\")\n",
    "print(f\"Outage rate: {merged_df['outage_occurred'].mean():.1%}\")\n",
    "print(f\"Date range: {merged_df['date'].min()} to {merged_df['date'].max()}\")\n",
    "print(f\"Columns: {list(merged_df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee35014",
   "metadata": {},
   "source": [
    "## Geographic Data Cleaning\n",
    "\n",
    "Clean and standardize geographic identifiers from weather data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b4e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract clean geographic data from weather dataset\n",
    "\n",
    "# Check if cleaning is already done\n",
    "if 'county_name' not in merged_df.columns:\n",
    "    print(\"Geographic cleaning already completed.\")\n",
    "    print(f\"Dataset: {merged_df.shape[0]:,} observations across {merged_df['state'].nunique()} states, {merged_df['county'].nunique()} counties\")\n",
    "else:\n",
    "    print(\"Extracting clean geographic data...\")\n",
    "    \n",
    "    # State abbreviation mapping\n",
    "    state_map = {\n",
    "        'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California',\n",
    "        'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia',\n",
    "        'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa',\n",
    "        'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "        'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri',\n",
    "        'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico', 'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont',\n",
    "        'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming',\n",
    "        'DC': 'District of Columbia'\n",
    "    }\n",
    "\n",
    "    # Extract from county_name format: \"ST: County Name\"\n",
    "    merged_df['state'] = merged_df['county_name'].str.split(':').str[0].map(state_map)\n",
    "    merged_df['county'] = merged_df['county_name'].str.split(':').str[1].str.strip()\n",
    "    \n",
    "    # Clean up\n",
    "    merged_df = merged_df.drop('county_name', axis=1)\n",
    "    print(\"Geographic cleaning completed!\")\n",
    "\n",
    "# Final dataset summary\n",
    "print(f\"\\nIntegrated Dataset Summary:\")\n",
    "print(f\"Shape: {merged_df.shape}\")\n",
    "print(f\"Coverage: {merged_df['state'].nunique()} states, {merged_df['county'].nunique()} counties\")\n",
    "print(f\"Outage rate: {merged_df['outage_occurred'].mean():.1%}\")\n",
    "\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03253490",
   "metadata": {},
   "source": [
    "## Temporal Feature Engineering\n",
    "\n",
    "Extract meaningful temporal components for predictive modeling.\n",
    "\n",
    "**Rationale for Temporal Decomposition**\n",
    "\n",
    "Raw dates are poor features for machine learning models. Decomposing dates into components allows models to:\n",
    "- **Learn seasonal patterns**: Winter vs summer outage rates\n",
    "- **Detect weekly cycles**: Weekend vs weekday maintenance patterns  \n",
    "- **Identify peak hours**: Time-of-day when outages are most likely\n",
    "- **Capture trends**: Multi-year infrastructure changes\n",
    "\n",
    "**Feature Extraction Strategy**\n",
    "- From `date`: Month, day of week, season, year (for all observations)\n",
    "- From `run_start_time`: Hour of day (only for outage events - when timing matters)\n",
    "- Preserve original `date` for sorting and potential date-based joins\n",
    "- Keep `run_start_time` for detailed temporal analysis of outage events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03167449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal feature engineering\n",
    "\n",
    "print(\"Extracting temporal features...\")\n",
    "\n",
    "# Extract date components (for all observations)\n",
    "merged_df['year'] = merged_df['date'].dt.year\n",
    "merged_df['month'] = merged_df['date'].dt.month\n",
    "merged_df['day_of_week'] = merged_df['date'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "merged_df['day_name'] = merged_df['date'].dt.day_name()\n",
    "\n",
    "# Create season feature\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "\n",
    "merged_df['season'] = merged_df['month'].apply(get_season)\n",
    "\n",
    "# Extract hour from run_start_time (only for outage events)\n",
    "merged_df['outage_hour'] = merged_df['run_start_time'].dt.hour\n",
    "\n",
    "print(\"Temporal features extracted!\")\n",
    "\n",
    "# Show summary of new features\n",
    "print(f\"\\nTemporal Feature Summary:\")\n",
    "print(f\"Years covered: {merged_df['year'].min()} - {merged_df['year'].max()}\")\n",
    "print(f\"Seasons: {merged_df['season'].value_counts().to_dict()}\")\n",
    "print(f\"Day of week distribution: {merged_df['day_name'].value_counts().to_dict()}\")\n",
    "\n",
    "# Show outage hour distribution (only for actual outages)\n",
    "outage_hours = merged_df[merged_df['outage_occurred'] == 1]['outage_hour'].value_counts().sort_index()\n",
    "print(f\"\\nOutage hour distribution (top 5):\")\n",
    "print(outage_hours.head())\n",
    "\n",
    "print(f\"\\nDataset shape after temporal features: {merged_df.shape}\")\n",
    "print(f\"New columns: {list(merged_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83136a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample observations with new temporal features\n",
    "\n",
    "print(\"Sample observations showing temporal features:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show outage events with temporal details\n",
    "print(\"\\nOutage events with temporal context:\")\n",
    "outage_sample = merged_df[merged_df['outage_occurred'] == 1].head(5)\n",
    "display(outage_sample[['county', 'state', 'date', 'year', 'month', 'season', 'day_name', \n",
    "                      'outage_hour', 'customers_out', 'run_start_time']])\n",
    "\n",
    "# Show no-outage events \n",
    "print(\"\\nNo-outage events with temporal context:\")\n",
    "no_outage_sample = merged_df[merged_df['outage_occurred'] == 0].head(5)\n",
    "display(no_outage_sample[['county', 'state', 'date', 'year', 'month', 'season', 'day_name', \n",
    "                         'outage_hour', 'customers_out', 'run_start_time']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249d7028",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis for Predictive Modeling\n",
    "\n",
    "**Objective**: Analyze patterns and relationships to support **≥85% accuracy** outage prediction model.\n",
    "\n",
    "**Key Analysis Areas**:\n",
    "1. **Target Variable Analysis**: Class balance and temporal patterns\n",
    "2. **Weather Threshold Analysis**: Critical thresholds for outage prediction  \n",
    "3. **Temporal Patterns**: Seasonal, monthly, and hourly outage risks\n",
    "4. **Geographic Risk Assessment**: High-risk regions and baseline rates\n",
    "5. **Feature Relationships**: Correlations and interaction effects\n",
    "6. **Baseline Model Insights**: Simple rules for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dataset Overview and Target Analysis\n",
    "\n",
    "print(\"POWER OUTAGE PREDICTION - EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Basic dataset characteristics\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"Total observations: {len(merged_df):,}\")\n",
    "print(f\"Variables: {len(merged_df.columns)}\")\n",
    "print(f\"Time span: {(merged_df['date'].max() - merged_df['date'].min()).days} days ({merged_df['year'].min()}-{merged_df['year'].max()})\")\n",
    "print(f\"Geographic coverage: {merged_df['fips_code'].nunique()} counties across {merged_df['state'].nunique()} states\")\n",
    "\n",
    "# Target variable analysis\n",
    "outage_counts = merged_df['outage_occurred'].value_counts()\n",
    "outage_rate = merged_df['outage_occurred'].mean()\n",
    "\n",
    "print(f\"\\nTarget Variable Analysis:\")\n",
    "print(f\"Overall outage rate: {outage_rate:.1%}\")\n",
    "print(f\"No outage (0): {outage_counts[0]:,} observations ({outage_counts[0]/len(merged_df):.1%})\")\n",
    "print(f\"Outage (1): {outage_counts[1]:,} observations ({outage_counts[1]/len(merged_df):.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b75b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Weather Threshold Analysis\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"WEATHER THRESHOLD ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Find weather thresholds where outage rates spike\n",
    "def analyze_weather_thresholds(var_name, thresholds):\n",
    "    print(f\"\\n{var_name.upper()} Threshold Analysis:\")\n",
    "    var_data = merged_df[var_name]\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        if 'min' in var_name:\n",
    "            condition = var_data <= threshold\n",
    "            operator = \"≤\"\n",
    "        else:\n",
    "            condition = var_data >= threshold  \n",
    "            operator = \"≥\"\n",
    "            \n",
    "        subset = merged_df[condition]\n",
    "        if len(subset) > 100:  # Only analyze if sufficient data\n",
    "            outage_rate = subset['outage_occurred'].mean()\n",
    "            baseline_rate = merged_df['outage_occurred'].mean()\n",
    "            risk_ratio = outage_rate / baseline_rate\n",
    "            \n",
    "            print(f\"  {var_name} {operator} {threshold}: {outage_rate:.1%} outage rate \"\n",
    "                  f\"({len(subset):,} observations, {risk_ratio:.1f}x baseline)\")\n",
    "\n",
    "# Temperature thresholds\n",
    "analyze_weather_thresholds('tmin', [-20, -15, -10, -5, 0])\n",
    "analyze_weather_thresholds('tmax', [30, 35, 40, 45])\n",
    "\n",
    "# Precipitation thresholds  \n",
    "analyze_weather_thresholds('prcp', [10, 20, 25, 30, 50, 75])\n",
    "\n",
    "print(f\"\\nWeather variable summary statistics:\")\n",
    "weather_stats = merged_df[['tmax', 'tmin', 'prcp']].describe()\n",
    "display(weather_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f6c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Temporal Pattern Analysis\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TEMPORAL PATTERN ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Monthly patterns\n",
    "print(\"\\nMonthly Outage Patterns:\")\n",
    "monthly_stats = merged_df.groupby('month')['outage_occurred'].agg(['count', 'mean']).round(3)\n",
    "monthly_stats.columns = ['observations', 'outage_rate']\n",
    "monthly_stats = monthly_stats.reindex(['January', 'February', 'March', 'April', 'May', 'June',\n",
    "                                     'July', 'August', 'September', 'October', 'November', 'December'])\n",
    "display(monthly_stats)\n",
    "\n",
    "# Seasonal patterns\n",
    "print(\"\\nSeasonal Outage Patterns:\")\n",
    "seasonal_stats = merged_df.groupby('season')['outage_occurred'].agg(['count', 'mean']).round(3)\n",
    "seasonal_stats.columns = ['observations', 'outage_rate']\n",
    "display(seasonal_stats)\n",
    "\n",
    "# Day of week patterns\n",
    "print(\"\\nDay of Week Patterns:\")\n",
    "dow_stats = merged_df.groupby('day_of_week')['outage_occurred'].agg(['count', 'mean']).round(3)\n",
    "dow_stats.columns = ['observations', 'outage_rate']\n",
    "dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_stats = dow_stats.reindex(dow_order)\n",
    "display(dow_stats)\n",
    "\n",
    "# Hourly patterns (if available)\n",
    "if 'outage_hour' in merged_df.columns:\n",
    "    print(\"\\nHourly Outage Patterns:\")\n",
    "    hourly_stats = merged_df.groupby('outage_hour')['outage_occurred'].agg(['count', 'mean']).round(3)\n",
    "    hourly_stats.columns = ['observations', 'outage_rate']\n",
    "    print(f\"Peak hour: {hourly_stats['outage_rate'].idxmax()}:00 with {hourly_stats['outage_rate'].max():.1%} rate\")\n",
    "    print(f\"Low hour: {hourly_stats['outage_rate'].idxmin()}:00 with {hourly_stats['outage_rate'].min():.1%} rate\")\n",
    "\n",
    "# Year over year trends\n",
    "print(\"\\nYear-over-Year Trends:\")\n",
    "yearly_stats = merged_df.groupby('year')['outage_occurred'].agg(['count', 'mean']).round(3)\n",
    "yearly_stats.columns = ['observations', 'outage_rate']\n",
    "display(yearly_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ab4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Geographic Risk Assessment\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GEOGRAPHIC RISK ASSESSMENT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# State-level analysis\n",
    "print(\"\\nTop 10 States by Outage Rate:\")\n",
    "state_stats = merged_df.groupby('state')['outage_occurred'].agg(['count', 'mean']).round(3)\n",
    "state_stats.columns = ['observations', 'outage_rate']\n",
    "state_stats = state_stats[state_stats['observations'] >= 1000]  # Minimum sample size\n",
    "top_states = state_stats.sort_values('outage_rate', ascending=False).head(10)\n",
    "display(top_states)\n",
    "\n",
    "print(\"\\nBottom 10 States by Outage Rate:\")\n",
    "bottom_states = state_stats.sort_values('outage_rate', ascending=True).head(10)\n",
    "display(bottom_states)\n",
    "\n",
    "# County-level analysis  \n",
    "print(\"\\nTop 10 Counties by Outage Rate (min 500 observations):\")\n",
    "county_stats = merged_df.groupby(['state', 'county'])['outage_occurred'].agg(['count', 'mean']).round(3)\n",
    "county_stats.columns = ['observations', 'outage_rate']\n",
    "county_stats = county_stats[county_stats['observations'] >= 500]\n",
    "top_counties = county_stats.sort_values('outage_rate', ascending=False).head(10)\n",
    "display(top_counties)\n",
    "\n",
    "# Geographic coverage summary\n",
    "print(f\"\\nGeographic Coverage Summary:\")\n",
    "print(f\"  States: {merged_df['state'].nunique()}\")\n",
    "print(f\"  Counties: {merged_df['county'].nunique()}\")\n",
    "print(f\"  FIPS codes: {merged_df['fips_code'].nunique()}\")\n",
    "\n",
    "# Regional patterns\n",
    "if 'state' in merged_df.columns:\n",
    "    # Define regions\n",
    "    regions = {\n",
    "        'Northeast': ['Maine', 'New Hampshire', 'Vermont', 'Massachusetts', 'Rhode Island', 'Connecticut', \n",
    "                     'New York', 'New Jersey', 'Pennsylvania'],\n",
    "        'Southeast': ['Delaware', 'Maryland', 'Virginia', 'West Virginia', 'Kentucky', 'Tennessee',\n",
    "                     'North Carolina', 'South Carolina', 'Georgia', 'Florida', 'Alabama', 'Mississippi', 'Arkansas', 'Louisiana'],\n",
    "        'Midwest': ['Ohio', 'Indiana', 'Illinois', 'Michigan', 'Wisconsin', 'Minnesota', 'Iowa', 'Missouri',\n",
    "                   'North Dakota', 'South Dakota', 'Nebraska', 'Kansas'],\n",
    "        'Southwest': ['Texas', 'Oklahoma', 'New Mexico', 'Arizona'],\n",
    "        'West': ['Colorado', 'Wyoming', 'Montana', 'Idaho', 'Washington', 'Oregon', 'Utah', 'Nevada', 'California',\n",
    "                'Alaska', 'Hawaii']\n",
    "    }\n",
    "    \n",
    "    # Create region mapping\n",
    "    state_to_region = {}\n",
    "    for region, states in regions.items():\n",
    "        for state in states:\n",
    "            state_to_region[state] = region\n",
    "    \n",
    "    merged_df['region'] = merged_df['state'].map(state_to_region)\n",
    "    \n",
    "    print(\"\\nRegional Outage Patterns:\")\n",
    "    regional_stats = merged_df.groupby('region')['outage_occurred'].agg(['count', 'mean']).round(3)\n",
    "    regional_stats.columns = ['observations', 'outage_rate']\n",
    "    display(regional_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "652e9635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated dataset saved to: ../../data/processed/integrated_dataset.csv\n",
      "Dataset shape: (3976135, 17)\n",
      "Ready for downstream analysis and modeling.\n"
     ]
    }
   ],
   "source": [
    "# Save the integrated dataset for downstream notebooks\n",
    "print(\"Saving integrated dataset...\")\n",
    "\n",
    "# Create processed data directory if it doesn't exist\n",
    "processed_dir = Path(\"../../data/processed\")\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save the integrated dataset\n",
    "output_file = processed_dir / \"integrated_dataset.csv\"\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Integrated dataset saved to: {output_file}\")\n",
    "print(f\"Dataset shape: {merged_df.shape}\")\n",
    "print(\"Ready for downstream analysis and modeling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66c8b434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "WEATHER-OUTAGE CORRELATION ANALYSIS\n",
      "==================================================\n",
      "TMAX correlation with outages: -0.0165\n",
      "TMIN correlation with outages: -0.0208\n",
      "PRCP correlation with outages: -0.0025\n",
      "\n",
      "Weather Distributions by Outage Status:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">tmax</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tmin</th>\n",
       "      <th colspan=\"2\" halign=\"left\">prcp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outage_occurred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.17</td>\n",
       "      <td>11.54</td>\n",
       "      <td>6.23</td>\n",
       "      <td>10.83</td>\n",
       "      <td>2.95</td>\n",
       "      <td>7.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.78</td>\n",
       "      <td>11.61</td>\n",
       "      <td>5.78</td>\n",
       "      <td>10.64</td>\n",
       "      <td>2.91</td>\n",
       "      <td>7.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tmax         tmin         prcp      \n",
       "                  mean    std  mean    std  mean   std\n",
       "outage_occurred                                       \n",
       "0                18.17  11.54  6.23  10.83  2.95  7.76\n",
       "1                17.78  11.61  5.78  10.64  2.91  7.54"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extreme Weather Event Analysis:\n",
      "TMAX ≥ 33.2: 47.3% outage rate (199,380 observations, 1.0x baseline)\n",
      "TMIN ≤ -12.9: 43.8% outage rate (198,857 observations, 0.9x baseline)\n",
      "PRCP ≥ 16.5: 46.2% outage rate (198,981 observations, 1.0x baseline)\n",
      "\n",
      "Combined Weather Stress Events:\n",
      "High temp + high precip: 46.1% outage rate (168,250 observations)\n",
      "Cold + high precip: 46.9% outage rate (73,985 observations)\n"
     ]
    }
   ],
   "source": [
    "# 5. Weather-Outage Correlation Analysis\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"WEATHER-OUTAGE CORRELATION ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate correlations with target variable\n",
    "weather_vars = ['tmax', 'tmin', 'prcp']\n",
    "correlations = {}\n",
    "\n",
    "for var in weather_vars:\n",
    "    corr = merged_df[var].corr(merged_df['outage_occurred'])\n",
    "    correlations[var] = corr\n",
    "    print(f\"{var.upper()} correlation with outages: {corr:.4f}\")\n",
    "\n",
    "# Weather variable distributions by outage status\n",
    "print(\"\\nWeather Distributions by Outage Status:\")\n",
    "weather_comparison = merged_df.groupby('outage_occurred')[weather_vars].agg(['mean', 'std']).round(2)\n",
    "display(weather_comparison)\n",
    "\n",
    "# Extreme weather analysis\n",
    "print(\"\\nExtreme Weather Event Analysis:\")\n",
    "\n",
    "# Define extreme thresholds based on percentiles\n",
    "extreme_thresholds = {\n",
    "    'tmax_extreme': merged_df['tmax'].quantile(0.95),\n",
    "    'tmin_extreme': merged_df['tmin'].quantile(0.05),\n",
    "    'prcp_extreme': merged_df['prcp'].quantile(0.95)\n",
    "}\n",
    "\n",
    "for event, threshold in extreme_thresholds.items():\n",
    "    var_name = event.split('_')[0]\n",
    "    if 'min' in event:\n",
    "        condition = merged_df[var_name] <= threshold\n",
    "        operator = \"≤\"\n",
    "    else:\n",
    "        condition = merged_df[var_name] >= threshold\n",
    "        operator = \"≥\"\n",
    "    \n",
    "    extreme_subset = merged_df[condition]\n",
    "    outage_rate = extreme_subset['outage_occurred'].mean()\n",
    "    baseline_rate = merged_df['outage_occurred'].mean()\n",
    "    \n",
    "    print(f\"{var_name.upper()} {operator} {threshold:.1f}: {outage_rate:.1%} outage rate \"\n",
    "          f\"({len(extreme_subset):,} observations, {outage_rate/baseline_rate:.1f}x baseline)\")\n",
    "\n",
    "# Combined weather stress analysis\n",
    "print(\"\\nCombined Weather Stress Events:\")\n",
    "# High temp + high precip\n",
    "hot_wet = (merged_df['tmax'] >= merged_df['tmax'].quantile(0.8)) & (merged_df['prcp'] >= merged_df['prcp'].quantile(0.8))\n",
    "hot_wet_rate = merged_df[hot_wet]['outage_occurred'].mean()\n",
    "print(f\"High temp + high precip: {hot_wet_rate:.1%} outage rate ({hot_wet.sum():,} observations)\")\n",
    "\n",
    "# Cold + precip\n",
    "cold_wet = (merged_df['tmin'] <= merged_df['tmin'].quantile(0.2)) & (merged_df['prcp'] >= merged_df['prcp'].quantile(0.8))\n",
    "cold_wet_rate = merged_df[cold_wet]['outage_occurred'].mean()\n",
    "print(f\"Cold + high precip: {cold_wet_rate:.1%} outage rate ({cold_wet.sum():,} observations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbb80f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DESCRIPTIVE STATISTICS\n",
      "============================================================\n",
      "\n",
      "MAIN STATISTICS TABLE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Count</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tmax</td>\n",
       "      <td>3,976,135</td>\n",
       "      <td>17.989</td>\n",
       "      <td>20.040</td>\n",
       "      <td>11.577</td>\n",
       "      <td>134.023</td>\n",
       "      <td>-30.860</td>\n",
       "      <td>48.570</td>\n",
       "      <td>-0.569</td>\n",
       "      <td>-0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tmin</td>\n",
       "      <td>3,976,135</td>\n",
       "      <td>6.021</td>\n",
       "      <td>6.650</td>\n",
       "      <td>10.747</td>\n",
       "      <td>115.508</td>\n",
       "      <td>-42.620</td>\n",
       "      <td>32.110</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>-0.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prcp</td>\n",
       "      <td>3,976,135</td>\n",
       "      <td>2.933</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.656</td>\n",
       "      <td>58.612</td>\n",
       "      <td>0.000</td>\n",
       "      <td>330.800</td>\n",
       "      <td>5.622</td>\n",
       "      <td>57.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>customers_out</td>\n",
       "      <td>3,976,135</td>\n",
       "      <td>39.339</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1288.945</td>\n",
       "      <td>1661378.721</td>\n",
       "      <td>0.000</td>\n",
       "      <td>709360.000</td>\n",
       "      <td>195.098</td>\n",
       "      <td>64874.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outage_occurred</td>\n",
       "      <td>3,976,135</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.149</td>\n",
       "      <td>-1.978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Variable      Count    Mean  Median   Std Dev     Variance      Min  \\\n",
       "0             tmax  3,976,135  17.989  20.040    11.577      134.023  -30.860   \n",
       "1             tmin  3,976,135   6.021   6.650    10.747      115.508  -42.620   \n",
       "2             prcp  3,976,135   2.933   0.000     7.656       58.612    0.000   \n",
       "3    customers_out  3,976,135  39.339   0.000  1288.945  1661378.721    0.000   \n",
       "4  outage_occurred  3,976,135   0.463   0.000     0.499        0.249    0.000   \n",
       "\n",
       "          Max Skewness   Kurtosis  \n",
       "0      48.570   -0.569     -0.435  \n",
       "1      32.110   -0.464     -0.191  \n",
       "2     330.800    5.622     57.841  \n",
       "3  709360.000  195.098  64874.067  \n",
       "4       1.000    0.149     -1.978  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PERCENTILES TABLE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>5th</th>\n",
       "      <th>25th</th>\n",
       "      <th>50th</th>\n",
       "      <th>75th</th>\n",
       "      <th>95th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tmax</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>9.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.6</td>\n",
       "      <td>33.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tmin</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prcp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>customers_out</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outage_occurred</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Variable    5th  25th  50th  75th  95th\n",
       "0             tmax   -2.7   9.6  20.0  27.6  33.2\n",
       "1             tmin  -12.9  -1.3   6.7  14.7  21.6\n",
       "2             prcp    0.0   0.0   0.0   2.0  16.5\n",
       "3    customers_out    0.0   0.0   0.0   2.0  46.0\n",
       "4  outage_occurred    0.0   0.0   0.0   1.0   1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VARIABLE-SPECIFIC INSIGHTS:\n",
      "\n",
      "Temperature Analysis:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daily temp range (mean)</td>\n",
       "      <td>12.0°C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daily temp range (std)</td>\n",
       "      <td>4.1°C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extreme cold days (&lt; -20°C)</td>\n",
       "      <td>65,809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extreme hot days (&gt; 40°C)</td>\n",
       "      <td>1,465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Metric   Value\n",
       "0      Daily temp range (mean)  12.0°C\n",
       "1       Daily temp range (std)   4.1°C\n",
       "2  Extreme cold days (< -20°C)  65,809\n",
       "3    Extreme hot days (> 40°C)   1,465"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precipitation Analysis:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Days with precipitation</td>\n",
       "      <td>1,760,266 (44.3%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mean on rainy days</td>\n",
       "      <td>6.6mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Std on rainy days</td>\n",
       "      <td>10.4mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heavy rain days (&gt;25mm)</td>\n",
       "      <td>96,292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extreme rain days (&gt;75mm)</td>\n",
       "      <td>3,813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Metric              Value\n",
       "0    Days with precipitation  1,760,266 (44.3%)\n",
       "1         Mean on rainy days              6.6mm\n",
       "2          Std on rainy days             10.4mm\n",
       "3    Heavy rain days (>25mm)             96,292\n",
       "4  Extreme rain days (>75mm)              3,813"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Customer Impact Analysis:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Events with customer data</td>\n",
       "      <td>1,630,315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mean customers affected</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Std customers affected</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coefficient of variation</td>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Large outages (&gt;1000)</td>\n",
       "      <td>22,539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Major outages (&gt;10000)</td>\n",
       "      <td>1,722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Metric      Value\n",
       "0  Events with customer data  1,630,315\n",
       "1    Mean customers affected         96\n",
       "2     Std customers affected       2012\n",
       "3   Coefficient of variation      20.97\n",
       "4      Large outages (>1000)     22,539\n",
       "5     Major outages (>10000)      1,722"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Descriptive Statistics\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create comprehensive statistics table\n",
    "key_vars = ['tmax', 'tmin', 'prcp', 'customers_out', 'outage_occurred']\n",
    "\n",
    "# Calculate all statistics\n",
    "stats_data = []\n",
    "for var in key_vars:\n",
    "    data = merged_df[var]\n",
    "    stats_data.append({\n",
    "        'Variable': var,\n",
    "        'Count': f\"{data.count():,}\",\n",
    "        'Mean': f\"{data.mean():.3f}\",\n",
    "        'Median': f\"{data.median():.3f}\",\n",
    "        'Std Dev': f\"{data.std():.3f}\",\n",
    "        'Variance': f\"{data.var():.3f}\",\n",
    "        'Min': f\"{data.min():.3f}\",\n",
    "        'Max': f\"{data.max():.3f}\",\n",
    "        'Skewness': f\"{data.skew():.3f}\",\n",
    "        'Kurtosis': f\"{data.kurtosis():.3f}\"\n",
    "    })\n",
    "\n",
    "stats_df = pd.DataFrame(stats_data)\n",
    "print(\"\\nMAIN STATISTICS TABLE:\")\n",
    "display(stats_df)\n",
    "\n",
    "# Create percentiles table\n",
    "print(\"\\nPERCENTILES TABLE:\")\n",
    "percentiles_data = []\n",
    "percentiles = [5, 25, 50, 75, 95]\n",
    "for var in key_vars:\n",
    "    data = merged_df[var]\n",
    "    row = {'Variable': var}\n",
    "    for p in percentiles:\n",
    "        row[f'{p}th'] = f\"{data.quantile(p/100):.1f}\"\n",
    "    percentiles_data.append(row)\n",
    "\n",
    "percentiles_df = pd.DataFrame(percentiles_data)\n",
    "display(percentiles_df)\n",
    "\n",
    "# Variable-specific insights table\n",
    "print(\"\\nVARIABLE-SPECIFIC INSIGHTS:\")\n",
    "\n",
    "# Temperature analysis\n",
    "temp_range = merged_df['tmax'] - merged_df['tmin']\n",
    "temp_stats = pd.DataFrame([\n",
    "    ['Daily temp range (mean)', f\"{temp_range.mean():.1f}°C\"],\n",
    "    ['Daily temp range (std)', f\"{temp_range.std():.1f}°C\"],\n",
    "    ['Extreme cold days (< -20°C)', f\"{(merged_df['tmin'] < -20).sum():,}\"],\n",
    "    ['Extreme hot days (> 40°C)', f\"{(merged_df['tmax'] > 40).sum():,}\"]\n",
    "], columns=['Metric', 'Value'])\n",
    "\n",
    "print(\"\\nTemperature Analysis:\")\n",
    "display(temp_stats)\n",
    "\n",
    "# Precipitation analysis\n",
    "prcp_nonzero = merged_df[merged_df['prcp'] > 0]['prcp']\n",
    "precip_stats = pd.DataFrame([\n",
    "    ['Days with precipitation', f\"{len(prcp_nonzero):,} ({len(prcp_nonzero)/len(merged_df):.1%})\"],\n",
    "    ['Mean on rainy days', f\"{prcp_nonzero.mean():.1f}mm\"],\n",
    "    ['Std on rainy days', f\"{prcp_nonzero.std():.1f}mm\"],\n",
    "    ['Heavy rain days (>25mm)', f\"{(merged_df['prcp'] > 25).sum():,}\"],\n",
    "    ['Extreme rain days (>75mm)', f\"{(merged_df['prcp'] > 75).sum():,}\"]\n",
    "], columns=['Metric', 'Value'])\n",
    "\n",
    "print(\"\\nPrecipitation Analysis:\")\n",
    "display(precip_stats)\n",
    "\n",
    "# Customer impact analysis\n",
    "customers_nonzero = merged_df[merged_df['customers_out'] > 0]['customers_out']\n",
    "customer_stats = pd.DataFrame([\n",
    "    ['Events with customer data', f\"{len(customers_nonzero):,}\"],\n",
    "    ['Mean customers affected', f\"{customers_nonzero.mean():.0f}\"],\n",
    "    ['Std customers affected', f\"{customers_nonzero.std():.0f}\"],\n",
    "    ['Coefficient of variation', f\"{customers_nonzero.std()/customers_nonzero.mean():.2f}\"],\n",
    "    ['Large outages (>1000)', f\"{(customers_nonzero > 1000).sum():,}\"],\n",
    "    ['Major outages (>10000)', f\"{(customers_nonzero > 10000).sum():,}\"]\n",
    "], columns=['Metric', 'Value'])\n",
    "\n",
    "print(\"\\nCustomer Impact Analysis:\")\n",
    "display(customer_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
