{"cells":[{"cell_type":"code","execution_count":6,"id":"9f2b3613","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9f2b3613","outputId":"00b19f29-d071-43ac-dbe4-fc7996c835f7","executionInfo":{"status":"ok","timestamp":1764967382876,"user_tz":300,"elapsed":557,"user":{"displayName":"Ann U","userId":"13375256159808411162"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Processed: /content/drive/MyDrive/ABT_Global/AI-Studio-Project/data/processed\n","Outputs: /content/drive/MyDrive/ABT_Global/AI-Studio-Project/notebooks/outputs/milestone_2\n"]}],"source":["from pathlib import Path\n","try:\n","    import google.colab\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=False)\n","    PROJECT_ROOT = Path(\"/content/drive/MyDrive/ABT_Global/AI-Studio-Project\")\n","except ImportError:\n","    PROJECT_ROOT = Path(\"../..\").resolve()\n","PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n","OUTPUTS = PROJECT_ROOT / \"notebooks\" / \"outputs\" / \"milestone_2\"\n","OUTPUTS.mkdir(parents=True, exist_ok=True)\n","print(f\"Processed: {PROCESSED}\")\n","print(f\"Outputs: {OUTPUTS}\")"]},{"cell_type":"markdown","id":"5ba04490","metadata":{"id":"5ba04490"},"source":["## Environment Setup"]},{"cell_type":"markdown","id":"a33f5f4a","metadata":{"id":"a33f5f4a"},"source":["\n","# 01 â€” Dimensionality Reduction\n","\n","**Milestone 2** Â· Power Outage Prediction\n","\n","This notebook performs dimensionality reduction on the **engineered features from Milestone 1**, selecting the most predictive subset for modeling. It uses univariate statistical methods (F-test, Mutual Information), correlation analysis, and optional PCA to identify the optimal feature set while preserving model performance.\n","\n","**Pipeline:**\n","1. Load engineered features from Milestone 1 (no duplicate feature engineering)\n","2. Apply univariate selection methods (F-test, Mutual Information)\n","3. Remove highly correlated features (multicollinearity reduction)\n","4. Optional PCA analysis for dimensionality insights\n","5. Select final compact feature set for modeling\n","\n","**Goal:** Reduce ~40+ engineered features to ~15 most predictive features, ensuring no data leakage and maintaining statistical rigor.\n"]},{"cell_type":"code","execution_count":7,"id":"d5ee89df","metadata":{"id":"d5ee89df","executionInfo":{"status":"ok","timestamp":1764967384562,"user_tz":300,"elapsed":4,"user":{"displayName":"Ann U","userId":"13375256159808411162"}}},"outputs":[],"source":["# === Setup ===\n","import json\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.decomposition import PCA\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"d222df6c","metadata":{"id":"d222df6c"},"source":["## Load data"]},{"cell_type":"code","execution_count":8,"id":"053c6051","metadata":{"id":"053c6051","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764967410296,"user_tz":300,"elapsed":24222,"user":{"displayName":"Ann U","userId":"13375256159808411162"}},"outputId":"312b7a8f-01d7-4a54-a1a3-af101dfb2b91"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded: engineered_features.csv (from Milestone 1) with shape (3976135, 48)\n","Total features available: 48\n","Sample columns: ['fips_code', 'date', 'prcp', 'tmax', 'tmin', 'outage_occurred', 'customers_out', 'county', 'state', 'run_start_time', 'year', 'month', 'day_of_week', 'day_name', 'month_name'] ...\n"]}],"source":["\n","# Load engineered features from Milestone 1 (04_feature_engineering_selection.ipynb)\n","engineered_features_path = PROCESSED / \"engineered_features.csv\"\n","\n","if engineered_features_path.exists():\n","    df = pd.read_csv(engineered_features_path)\n","    if 'date' in df.columns:\n","        df['date'] = pd.to_datetime(df['date'])\n","    source = \"engineered_features.csv (from Milestone 1)\"\n","else:\n","    raise FileNotFoundError(f\"Engineered features not found! Please run Milestone 1 notebook (04_feature_engineering_selection.ipynb) first. Expected: {engineered_features_path}\")\n","\n","print(f\"Loaded: {source} with shape {df.shape}\")\n","print(f\"Total features available: {len(df.columns)}\")\n","print(\"Sample columns:\", list(df.columns)[:15], \"...\")\n"]},{"cell_type":"markdown","id":"6c03d416","metadata":{"id":"6c03d416"},"source":["## Define target and exclude leakage / IDs"]},{"cell_type":"code","execution_count":9,"id":"4593a790","metadata":{"id":"4593a790","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764967424634,"user_tz":300,"elapsed":196,"user":{"displayName":"Ann U","userId":"13375256159808411162"}},"outputId":"1972356d-f5b6-45e5-de15-154b7b3bf8cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Features after excluding leakage/IDs: 25\n","Excluded 23 columns\n"]}],"source":["\n","# Target\n","if 'outage_occurred' not in df.columns:\n","    raise KeyError(\"Column 'outage_occurred' is required as the classification target.\")\n","\n","y = df['outage_occurred'].astype(int)\n","\n","# Columns to exclude from feature selection\n","# These were already identified and removed in Milestone 1 feature engineering\n","always_exclude = {\n","    # IDs / metadata\n","    'fips_code', 'county', 'state', 'region', 'date', 'county_name',\n","    # Leakage features (identified in Milestone 1)\n","    'run_start_time', 'customers_out', 'outage_hour',\n","    'state_risk_score', 'region_risk_score', 'state_risk_category', 'high_risk_state',\n","    # Temporal features excluded in Milestone 1\n","    'year',\n","    # Redundant features (keep better versions)\n","    'day_of_week', 'tmin_bin', 'tmax_bin', 'month_group',\n","    'day_of_year_sin', 'month_sin', 'day_of_week_cos',\n","    # Text labels\n","    'day_name', 'season'\n","}\n","\n","exclude_cols = [c for c in df.columns if c in always_exclude or c == 'outage_occurred']\n","\n","X = df.drop(columns=[c for c in exclude_cols if c in df.columns]).copy()\n","print(f\"Features after excluding leakage/IDs: {X.shape[1]}\")\n","print(f\"Excluded {len([c for c in exclude_cols if c in df.columns])} columns\")\n"]},{"cell_type":"markdown","id":"09fa1bd4","metadata":{"id":"09fa1bd4"},"source":["## Preprocess: encode categoricals and impute missing"]},{"cell_type":"code","execution_count":12,"id":"e05ecefd","metadata":{"id":"e05ecefd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764967587225,"user_tz":300,"elapsed":150,"user":{"displayName":"Ann U","userId":"13375256159808411162"}},"outputId":"3c92e18d-2db6-49ae-8db6-c07abce8ddb4"},"outputs":[{"output_type":"stream","name":"stdout","text":["All features are already numeric (encoded in Milestone 1)\n","\n","Handling missing values in 1 features:\n","  season_encoded: 3976135 missing (100.00%)\n","\n","Dropping columns with 100% missing values: ['season_encoded']\n","\n","Final preprocessed shape: (3976135, 24)\n","Ready for dimensionality reduction with 24 features\n"]}],"source":["\n","# Features were already encoded in Milestone 1, but check for any remaining categorical\n","cat_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n","if cat_cols:\n","    print(f\"Encoding {len(cat_cols)} remaining categorical columns: {cat_cols}\")\n","    for col in cat_cols:\n","        le = LabelEncoder()\n","        X[col] = le.fit_transform(X[col].astype(str))\n","else:\n","    print(\"All features are already numeric (encoded in Milestone 1)\")\n","\n","# Check and handle missing values\n","missing_summary = X.isnull().sum()\n","features_with_missing = missing_summary[missing_summary > 0]\n","\n","if len(features_with_missing) > 0:\n","    print(f\"\\nHandling missing values in {len(features_with_missing)} features:\")\n","    to_drop_100_missing = []\n","    for col, count in features_with_missing.items():\n","        print(f\"  {col}: {count} missing ({count/len(X)*100:.2f}%)\")\n","        if count == len(X): # If 100% missing\n","            to_drop_100_missing.append(col)\n","        elif pd.api.types.is_numeric_dtype(X[col]):\n","            X[col] = X[col].fillna(X[col].median())\n","        else:\n","            X[col] = X[col].fillna(X[col].mode().iloc[0])\n","\n","    if to_drop_100_missing:\n","        print(f\"\\nDropping columns with 100% missing values: {to_drop_100_missing}\")\n","        X = X.drop(columns=to_drop_100_missing)\n","else:\n","    print(\"No missing values found\")\n","\n","print(f\"\\nFinal preprocessed shape: {X.shape}\")\n","print(f\"Ready for dimensionality reduction with {X.shape[1]} features\")\n"]},{"cell_type":"markdown","id":"3a3d4e15","metadata":{"id":"3a3d4e15"},"source":["## Univariate selection: F-test and Mutual Information"]},{"cell_type":"code","execution_count":13,"id":"c803c34d","metadata":{"id":"c803c34d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764968304950,"user_tz":300,"elapsed":597811,"user":{"displayName":"Ann U","userId":"13375256159808411162"}},"outputId":"2c841b0b-a1cf-4bf9-dc3d-40fb9010323e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running univariate feature selection on 24 features...\n","Target: top 25 features from each method\n","\n","1. Computing F-statistics...\n","2. Computing Mutual Information scores...\n","âœ“ Saved univariate scores -> /content/drive/MyDrive/ABT_Global/AI-Studio-Project/data/processed/feature_scores_univariate.csv\n","\n","Top 25 features by F-statistic: 24\n","Top 25 features by Mutual Info: 24\n","\n"," Candidate pools:\n","   Union (F âˆª MI): 24 features\n","   Intersection (F âˆ© MI): 24 features\n"]}],"source":["\n","# Dimensionality reduction: select top K features using univariate methods\n","K = 25  # target number of features to select\n","\n","print(f\"Running univariate feature selection on {X.shape[1]} features...\")\n","print(f\"Target: top {K} features from each method\\n\")\n","\n","# F-test (ANOVA) - measures linear dependency with target\n","print(\"1. Computing F-statistics...\")\n","f_selector = SelectKBest(score_func=f_classif, k=min(K, X.shape[1]))\n","f_selector.fit(X, y)\n","f_scores = f_selector.scores_\n","f_rank = pd.Series(f_scores, index=X.columns).sort_values(ascending=False).rename(\"f_score\")\n","\n","# Mutual Information - captures nonlinear relationships\n","print(\"2. Computing Mutual Information scores...\")\n","mi_selector = SelectKBest(score_func=mutual_info_classif, k=min(K, X.shape[1]))\n","mi_selector.fit(X, y)\n","mi_scores = mi_selector.scores_\n","mi_rank = pd.Series(mi_scores, index=X.columns).sort_values(ascending=False).rename(\"mi_score\")\n","\n","# Combine rankings\n","rank_df = pd.concat([f_rank, mi_rank], axis=1).fillna(0)\n","rank_df['f_rank'] = rank_df['f_score'].rank(ascending=False)\n","rank_df['mi_rank'] = rank_df['mi_score'].rank(ascending=False)\n","rank_df['avg_rank'] = (rank_df['f_rank'] + rank_df['mi_rank']) / 2\n","rank_df = rank_df.sort_values('avg_rank', ascending=True)\n","\n","# Save detailed scores\n","rank_df.to_csv(PROCESSED / \"feature_scores_univariate.csv\", index=True)\n","print(f\"âœ“ Saved univariate scores -> {PROCESSED / 'feature_scores_univariate.csv'}\")\n","\n","# Select top features from each method\n","top_f  = f_rank.head(K).index.tolist()\n","top_mi = mi_rank.head(K).index.tolist()\n","\n","print(f\"\\nTop {K} features by F-statistic: {len(top_f)}\")\n","print(f\"Top {K} features by Mutual Info: {len(top_mi)}\")\n","\n","# Create candidate pools\n","cand_union = list(dict.fromkeys(top_f + top_mi))  # union, preserving order\n","cand_inter = [c for c in top_f if c in top_mi]    # intersection\n","\n","print(f\"\\n Candidate pools:\")\n","print(f\"   Union (F âˆª MI): {len(cand_union)} features\")\n","print(f\"   Intersection (F âˆ© MI): {len(cand_inter)} features\")\n"]},{"cell_type":"markdown","id":"dddb1e8b","metadata":{"id":"dddb1e8b"},"source":["## Correlation pruning (remove highly collinear features)"]},{"cell_type":"code","execution_count":14,"id":"2261733f","metadata":{"id":"2261733f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764968325765,"user_tz":300,"elapsed":8465,"user":{"displayName":"Ann U","userId":"13375256159808411162"}},"outputId":"7caa1ff0-2749-4dc6-8874-85ead574e1fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Correlation pruning (removing multicollinear features)...\n","   Removed 5 highly correlated features (|r| > 0.85):\n","     â€¢ month_cos (r=0.955 with day_of_year_cos)\n","     â€¢ tmin (r=0.982 with temp_avg)\n","     â€¢ tmin (r=0.935 with tmax)\n","     â€¢ temp_avg (r=0.985 with tmax)\n","     â€¢ day_of_year (r=0.997 with month)\n","     ... and 1 more pairs\n","   Removed 5 highly correlated features (|r| > 0.85):\n","     â€¢ month_cos (r=0.955 with day_of_year_cos)\n","     â€¢ tmin (r=0.982 with temp_avg)\n","     â€¢ tmin (r=0.935 with tmax)\n","     â€¢ temp_avg (r=0.985 with tmax)\n","     â€¢ day_of_year (r=0.997 with month)\n","     ... and 1 more pairs\n","\n","After correlation pruning:\n","   Union: 24 â†’ 19 features\n","   Intersection: 24 â†’ 19 features\n"]}],"source":["\n","def correlation_prune(cols, corr_threshold=0.85):\n","    \"\"\"\n","    Remove highly correlated features to reduce multicollinearity.\n","    Keeps the first feature in each correlated pair.\n","    \"\"\"\n","    if len(cols) <= 1:\n","        return cols\n","\n","    C = X[cols].corr().abs()\n","    # Upper triangle mask to avoid duplicates\n","    upper = C.where(np.triu(np.ones(C.shape), k=1).astype(bool))\n","\n","    to_drop = set()\n","    dropped_pairs = []\n","\n","    for c in upper.columns:\n","        if c in to_drop:\n","            continue\n","        high_corr = upper[c][upper[c] > corr_threshold]\n","        if not high_corr.empty:\n","            for corr_feat in high_corr.index:\n","                dropped_pairs.append((c, corr_feat, upper.loc[corr_feat, c]))\n","                to_drop.add(corr_feat)\n","\n","    kept = [c for c in cols if c not in to_drop]\n","\n","    if dropped_pairs:\n","        print(f\"   Removed {len(to_drop)} highly correlated features (|r| > {corr_threshold}):\")\n","        for feat1, feat2, corr in dropped_pairs[:5]:  # show first 5\n","            print(f\"     â€¢ {feat2} (r={corr:.3f} with {feat1})\")\n","        if len(dropped_pairs) > 5:\n","            print(f\"     ... and {len(dropped_pairs) - 5} more pairs\")\n","\n","    return kept\n","\n","print(\"\\nCorrelation pruning (removing multicollinear features)...\")\n","\n","# Prune both candidate pools\n","union_pruned = correlation_prune(cand_union, corr_threshold=0.85)\n","inter_pruned = correlation_prune(cand_inter, corr_threshold=0.85)\n","\n","print(f\"\\nAfter correlation pruning:\")\n","print(f\"   Union: {len(cand_union)} â†’ {len(union_pruned)} features\")\n","print(f\"   Intersection: {len(cand_inter)} â†’ {len(inter_pruned)} features\")\n"]},{"cell_type":"markdown","id":"9b8eb43a","metadata":{"id":"9b8eb43a"},"source":["## Optional PCA on continuous features (for reference)"]},{"cell_type":"code","execution_count":15,"id":"39dad8dc","metadata":{"id":"39dad8dc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764968338040,"user_tz":300,"elapsed":1227,"user":{"displayName":"Ann U","userId":"13375256159808411162"}},"outputId":"7820724f-353d-4370-d79c-fe58a79101ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["PCA numeric cols: 24 | components to reach 95% var: 13\n","Saved PCA EVR -> /content/drive/MyDrive/ABT_Global/AI-Studio-Project/data/processed/pca_explained_variance.csv\n"]}],"source":["\n","# We'll only run PCA on numeric columns as an auxiliary representation.\n","# Save explained-variance info; do not force components into final feature set by default.\n","num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n","if len(num_cols) >= 2:\n","    scaler = StandardScaler()\n","    Xs = scaler.fit_transform(X[num_cols])\n","    pca = PCA(n_components=None, random_state=42)\n","    pca.fit(Xs)\n","    evr = pca.explained_variance_ratio_\n","    cum_evr = np.cumsum(evr)\n","\n","    # Choose #components to reach >=95% variance\n","    n95 = int(np.searchsorted(cum_evr, 0.95) + 1)\n","    pca_info = pd.DataFrame({\n","        \"component\": np.arange(1, len(evr)+1),\n","        \"explained_variance_ratio\": evr,\n","        \"cumulative_evr\": cum_evr\n","    })\n","    pca_info.to_csv(PROCESSED / \"pca_explained_variance.csv\", index=False)\n","    print(f\"PCA numeric cols: {len(num_cols)} | components to reach 95% var: {n95}\")\n","    print(\"Saved PCA EVR ->\", PROCESSED / \"pca_explained_variance.csv\")\n","else:\n","    print(\"Not enough numeric columns for PCA (skipped).\")\n"]},{"cell_type":"markdown","id":"1b3918e0","metadata":{"id":"1b3918e0"},"source":["## Final feature selection (rule-based consolidation)"]},{"cell_type":"code","execution_count":17,"id":"0d951706","metadata":{"id":"0d951706","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764968347199,"user_tz":300,"elapsed":5,"user":{"displayName":"Ann U","userId":"13375256159808411162"}},"outputId":"34589d7e-5976-4968-e98f-8e9eb09fb913"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Final feature selection (target: 15 features)...\n","\n","Selected 19 features:\n","   â€¢ 19 from intersection (robust across both methods)\n","   â€¢ 0 additional from union\n","\n","Final Feature Set (ranked by importance):\n"," 1. is_weekend                F=  8166.1  MI=0.0865\n"," 2. day_of_week_sin           F=  5701.8  MI=0.0702\n"," 3. state_encoded             F=  3890.0  MI=0.0859\n"," 4. region_encoded            F=   854.0  MI=0.1155\n"," 5. prcp_category             F=    55.6  MI=0.1593\n"," 6. has_precipitation         F=    46.7  MI=0.1346\n"," 7. day_of_year_cos           F=  1497.4  MI=0.0033\n"," 8. extreme_cold              F=   521.9  MI=0.0070\n"," 9. month                     F=   149.4  MI=0.0407\n","10. temp_stress               F=    96.6  MI=0.0134\n","11. day                       F=    64.8  MI=0.0144\n","12. month_name                F=    46.1  MI=0.0427\n","13. tmax                      F=  1083.6  MI=0.0006\n","14. extreme_hot               F=    86.4  MI=0.0066\n","15. temp_range                F=   256.1  MI=0.0009\n","16. heavy_precipitation       F=     0.5  MI=0.0067\n","17. prcp_intensity            F=    24.6  MI=0.0005\n","18. combined_extreme          F=     9.3  MI=0.0000\n","19. high_risk_season          F=     0.0  MI=0.0000\n","\n","ðŸ’¾ Saved final features -> /content/drive/MyDrive/ABT_Global/AI-Studio-Project/data/processed/final_features.json\n"]}],"source":["\n","# Final feature selection strategy:\n","# 1. Start with intersection (features strong in both methods)\n","# 2. Add top union features until we reach target size\n","# 3. Prioritize features by average rank\n","\n","TARGET_K = 15  # final number of features for modeling\n","\n","print(f\"\\nFinal feature selection (target: {TARGET_K} features)...\")\n","\n","# Start with intersection (most robust)\n","final_feats = inter_pruned.copy()\n","\n","# Add from union if needed, sorted by average rank\n","if len(final_feats) < TARGET_K:\n","    # Get remaining union features, sorted by average rank\n","    remaining = [f for f in union_pruned if f not in final_feats]\n","    remaining_ranks = rank_df.loc[remaining, 'avg_rank'].sort_values()\n","\n","    for feat in remaining_ranks.index:\n","        if len(final_feats) >= TARGET_K:\n","            break\n","        final_feats.append(feat)\n","\n","print(f\"\\nSelected {len(final_feats)} features:\")\n","print(f\"   â€¢ {len(inter_pruned)} from intersection (robust across both methods)\")\n","print(f\"   â€¢ {len(final_feats) - len(inter_pruned)} additional from union\")\n","\n","# Display final features with their scores\n","print(\"\\nFinal Feature Set (ranked by importance):\")\n","final_rank_info = rank_df.loc[final_feats].sort_values('avg_rank')\n","for i, (feat, row) in enumerate(final_rank_info.iterrows(), 1):\n","    print(f\"{i:2d}. {feat:<25} F={row['f_score']:>8.1f}  MI={row['mi_score']:.4f}\")\n","\n","# Save final features\n","with open(PROCESSED / \"final_features.json\", \"w\") as f:\n","    json.dump(final_feats, f, indent=2)\n","print(f\"\\nðŸ’¾ Saved final features -> {PROCESSED / 'final_features.json'}\")\n"]},{"cell_type":"markdown","id":"9c368f39","metadata":{"id":"9c368f39"},"source":["## Save reduced dataset"]},{"cell_type":"code","execution_count":18,"id":"1cc1ffcc","metadata":{"id":"1cc1ffcc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764968393029,"user_tz":300,"elapsed":27657,"user":{"displayName":"Ann U","userId":"13375256159808411162"}},"outputId":"29ae1991-d229-4750-f47c-329dab62532a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Saved reduced dataset:\n","   CSV: /content/drive/MyDrive/ABT_Global/AI-Studio-Project/data/processed/reduced_dataset.csv\n","   Parquet: /content/drive/MyDrive/ABT_Global/AI-Studio-Project/data/processed/reduced_dataset.parquet\n","   Shape: (3976135, 24)\n","   Features: 19 + target + 4 metadata columns\n"]}],"source":["# Create reduced dataset with selected features\n","reduced = X[final_feats].copy()\n","reduced['outage_occurred'] = y.values\n","\n","# Keep metadata columns for analysis/evaluation\n","metadata_cols = ['date', 'fips_code', 'state', 'county']\n","for col in metadata_cols:\n","    if col in df.columns and col not in reduced.columns:\n","        reduced[col] = df[col]\n","\n","# Save as both CSV and Parquet\n","reduced_csv = PROCESSED / \"reduced_dataset.csv\"\n","reduced_parquet = PROCESSED / \"reduced_dataset.parquet\"\n","\n","reduced.to_csv(reduced_csv, index=False)\n","reduced.to_parquet(reduced_parquet, index=False)\n","\n","print(f\"\\n Saved reduced dataset:\")\n","print(f\"   CSV: {reduced_csv}\")\n","print(f\"   Parquet: {reduced_parquet}\")\n","print(f\"   Shape: {reduced.shape}\")\n","print(f\"   Features: {len(final_feats)} + target + {len([c for c in metadata_cols if c in reduced.columns])} metadata columns\")\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V5E1","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"}},"nbformat":4,"nbformat_minor":5}