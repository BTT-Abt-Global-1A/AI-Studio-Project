{"cells":[{"cell_type":"code","execution_count":2,"id":"9062b345","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9062b345","executionInfo":{"status":"ok","timestamp":1764968987446,"user_tz":300,"elapsed":1433,"user":{"displayName":"Ann U","userId":"13375256159808411162"}},"outputId":"63aa1b70-e843-48e7-c380-0a0efc9d3531"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Processed: /content/drive/MyDrive/ABT_Global/AI-Studio-Project/data/processed\n"]}],"source":["from pathlib import Path\n","try:\n","    import google.colab\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    PROJECT_ROOT = Path(\"/content/drive/MyDrive/ABT_Global/AI-Studio-Project\")\n","except ImportError:\n","    PROJECT_ROOT = Path(\"../..\").resolve()\n","PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n","PROCESSED.mkdir(parents=True, exist_ok=True)\n","print(f\"Processed: {PROCESSED}\")"]},{"cell_type":"markdown","id":"40e0275d","metadata":{"id":"40e0275d"},"source":["## Environment Setup"]},{"cell_type":"code","execution_count":5,"id":"2958bc26-77e9-4c87-8724-b2bae65468f4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2958bc26-77e9-4c87-8724-b2bae65468f4","executionInfo":{"status":"ok","timestamp":1764969225964,"user_tz":300,"elapsed":4612,"user":{"displayName":"Ann U","userId":"13375256159808411162"}},"outputId":"83f66353-6ddd-4890-c10c-428322f92f7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Date range: 2014-01-01 00:00:00 to 2020-12-31 00:00:00\n","Total samples: 3,976,135\n","Months distribution:\n","month\n","1     337435\n","2     307890\n","3     337435\n","4     326550\n","5     337435\n","6     326550\n","7     337435\n","8     337435\n","9     326550\n","10    337435\n","11    326550\n","12    337435\n","Name: count, dtype: int64\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import json\n","\n","# Load your reduced dataset using dynamic paths\n","df = pd.read_csv(PROCESSED / \"reduced_dataset.csv\")\n","\n","# Convert date column to datetime and extract month\n","df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n","df['month'] = df['date'].dt.month\n","\n","print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n","print(f\"Total samples: {len(df):,}\")\n","print(f\"Months distribution:\\n{df['month'].value_counts().sort_index()}\")\n","\n","def month_stratified_split(df, test_size=0.2, val_size=0.2, random_state=42, save_splits=True):\n","    \"\"\"\n","    Performs a stratified split of the DataFrame into training, validation, and test sets.\n","    Stratification is done based on both 'month' and 'outage' columns to ensure\n","    representative distributions in each split.\n","\n","    Args:\n","        df (pd.DataFrame): The input DataFrame containing 'date', 'month', and 'outage' columns.\n","        test_size (float): The proportion of the dataset to include in the test split.\n","        val_size (float): The proportion of the dataset to include in the validation split.\n","        random_state (int): Controls the shuffling applied to the data before applying the split.\n","        save_splits (bool): If True, saves the split DataFrames to CSV files in the PROCESSED directory.\n","\n","    Returns:\n","        tuple: A tuple containing the training, validation, and test DataFrames.\n","    \"\"\"\n","    # Ensure 'outage' column exists for stratification\n","    if 'outage_occurred' not in df.columns:\n","        print(\"Warning: 'outage' column not found. Stratification will only be done by 'month'.\")\n","        df['stratify_col'] = df['month'].astype(str)\n","    else:\n","        # Create a combined stratification column for month and outage\n","        df['stratify_col'] = df['month'].astype(str) + '_' + df['outage_occurred'].astype(str)\n","\n","    # First split: train_val and test set\n","    train_val_df, test_df = train_test_split(\n","        df,\n","        test_size=test_size,\n","        random_state=random_state,\n","        stratify=df['stratify_col']\n","    )\n","\n","    # Calculate adjusted validation size for the second split\n","    # val_size is relative to the original DataFrame, we need it relative to train_val_df\n","    val_size_adjusted = val_size / (1 - test_size)\n","\n","    # Second split: train and validation set from train_val_df\n","    train_df, val_df = train_test_split(\n","        train_val_df,\n","        test_size=val_size_adjusted,\n","        random_state=random_state,\n","        stratify=train_val_df['stratify_col']\n","    )\n","\n","    # Drop the temporary stratification column from all splits\n","    train_df = train_df.drop(columns=['stratify_col'])\n","    val_df = val_df.drop(columns=['stratify_col'])\n","    test_df = test_df.drop(columns=['stratify_col'])\n","\n","    print(\"\\n--- Data Split Summary ---\")\n","    print(f\"Train samples: {len(train_df):,}\")\n","    print(f\"Validation samples: {len(val_df):,}\")\n","    print(f\"Test samples: {len(test_df):,}\")\n","\n","    print(\"\\nMonth Distribution in Splits:\")\n","    print(\"Train (%):\\n\", train_df['month'].value_counts(normalize=True).sort_index() * 100)\n","    print(\"Validation (%):\\n\", val_df['month'].value_counts(normalize=True).sort_index() * 100)\n","    print(\"Test (%):\\n\", test_df['month'].value_counts(normalize=True).sort_index() * 100)\n","\n","    if 'outage' in df.columns:\n","        print(\"\\nOutage Distribution in Splits:\")\n","        print(\"Train (%):\\n\", train_df['outage_occurred'].value_counts(normalize=True).sort_index() * 100)\n","        print(\"Validation (%):\\n\", val_df['outage_occurred'].value_counts(normalize=True).sort_index() * 100)\n","        print(\"Test (%):\\n\", test_df['outage_occurred'].value_counts(normalize=True).sort_index() * 100)\n","\n","    if save_splits:\n","        PROCESSED.mkdir(parents=True, exist_ok=True) # Ensure directory exists\n","        train_df.to_csv(PROCESSED / \"train_df.csv\", index=False)\n","        val_df.to_csv(PROCESSED / \"val_df.csv\", index=False)\n","        test_df.to_csv(PROCESSED / \"test_df.csv\", index=False)\n","        print(f\"\\nSplits saved to {PROCESSED}/\")\n","\n","    return train_df, val_df, test_df"]},{"cell_type":"code","metadata":{"id":"fdb74bf1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764969269940,"user_tz":300,"elapsed":41701,"user":{"displayName":"Ann U","userId":"13375256159808411162"}},"outputId":"adae2bfc-afd9-4ef9-f500-72aaa6c882d8"},"source":["train_df, val_df, test_df = month_stratified_split(df, test_size=0.2, val_size=0.2, random_state=42, save_splits=True)\n"],"id":"fdb74bf1","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Data Split Summary ---\n","Train samples: 2,385,681\n","Validation samples: 795,227\n","Test samples: 795,227\n","\n","Month Distribution in Splits:\n","Train (%):\n"," month\n","1     8.486508\n","2     7.743449\n","3     8.486508\n","4     8.212749\n","5     8.486508\n","6     8.212749\n","7     8.486508\n","8     8.486508\n","9     8.212749\n","10    8.486508\n","11    8.212749\n","12    8.486508\n","Name: proportion, dtype: float64\n","Validation (%):\n"," month\n","1     8.486508\n","2     7.743449\n","3     8.486508\n","4     8.212749\n","5     8.486508\n","6     8.212749\n","7     8.486508\n","8     8.486508\n","9     8.212749\n","10    8.486508\n","11    8.212749\n","12    8.486508\n","Name: proportion, dtype: float64\n","Test (%):\n"," month\n","1     8.486508\n","2     7.743449\n","3     8.486508\n","4     8.212749\n","5     8.486508\n","6     8.212749\n","7     8.486508\n","8     8.486508\n","9     8.212749\n","10    8.486508\n","11    8.212749\n","12    8.486508\n","Name: proportion, dtype: float64\n","\n","Splits saved to /content/drive/MyDrive/ABT_Global/AI-Studio-Project/data/processed/\n"]}]},{"cell_type":"markdown","id":"4c744e12-1e8c-4e47-b3b3-3b68e554b85e","metadata":{"id":"4c744e12-1e8c-4e47-b3b3-3b68e554b85e"},"source":["## Data Split Summary\n","\n","### Dataset Characteristics\n","- **Monthly Distribution**: Relatively balanced across months (8.2-8.5% per month)\n","- **Class Imbalance**: ~90.6% non-outage (Class 0) vs ~9.4% outage (Class 1) events\n","\n","### Split Configuration\n","- **Training Set**: (60%)\n","- **Validation Set**: (20%)\n","- **Test Set**: (20%)\n","\n","### Methodological Strengths\n","- **Seasonal Representation**: Each split contains proportional representation of all 12 months\n","- **Reduced Seasonal Bias**: Models learn from entire year's patterns across all splits which prevents overfitting to specific months\n","- **Class Distribution Preservation**: Maintains consistent outage/non-outage ratios (90.6%/9.4%)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V5E1"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":5}